{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 35 \n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pickles(): \n",
    "    x_train = pickle.load(open(f'../../data/processed/pickles/basin_x_train.p', 'rb'))\n",
    "    x_test = pickle.load(open(f'../../data/processed/pickles/basin_x_test.p', 'rb'))\n",
    "    y_train = pickle.load(open(f'../../data/processed/pickles/basin_y_train.p', 'rb'))\n",
    "    y_test = pickle.load(open(f'../../data/processed/pickles/basin_y_test.p', 'rb'))\n",
    "    X = pickle.load(open('../../data/processed/pickles/basin_X.p', 'rb'))\n",
    "    y = pickle.load(open('../../data/processed/pickles/basin_y.p', 'rb'))\n",
    "\n",
    "    return (x_train, x_test, y_train, y_test), (X,y)\n",
    "\n",
    "(x_train, x_test, y_train, y_test), (X,y) = get_pickles()\n",
    "\n",
    "unique_basin = X.basin.unique() \n",
    "print(f'Original X: {X.shape}\\tOriginal y: {y.shape}')\n",
    "print(f'Train X: {x_train.shape}\\tTrain y: {y_train.shape}')\n",
    "print(f'Test X: {x_test.shape}\\tTest y: {y_test.shape}')\n",
    "\n",
    "y_train = y_train.target.values.ravel()\n",
    "y_test = y_test.target.values.ravel()\n",
    "y = y.target.values.ravel()\n",
    "\n",
    "standard = StandardScaler() \n",
    "x_train[['amount_tsh', 'gps_height', \n",
    "         'population', 'time_passed']] = standard.fit_transform(x_train[['amount_tsh', \n",
    "                                                                         'gps_height', 'population', 'time_passed']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['target'] = y\n",
    "x_test['target'] = y_test\n",
    "x_train['target'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "scores = []\n",
    "basins = []\n",
    "basin_model_dict= {} \n",
    "pbar = os.listdir('../../data/processed/pickles/basins/')\n",
    "for i in os.listdir('../../data/processed/pickles/basins/'):\n",
    "    if i == '.DS_Store': \n",
    "        continue \n",
    "    basins.append(i)\n",
    "    #pbar.set_description(f'Testing Classifier for: {i.upper()}')\n",
    "    x_train = pickle.load(open(f'../../data/processed/pickles/basins/{i}/x_train.p', 'rb'))\n",
    "    x_test = pickle.load(open(f'../../data/processed/pickles/basins/{i}/x_test.p', 'rb'))\n",
    "    y_train = pickle.load(open(f'../../data/processed/pickles/basins/{i}/y_train.p', 'rb'))\n",
    "    y_test = pickle.load(open(f'../../data/processed/pickles/basins/{i}/y_test.p', 'rb'))\n",
    "    \n",
    "    x_train.drop('basin', axis =1, inplace = True)\n",
    "    x_test.drop('basin', axis =1, inplace = True)\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "   \n",
    "    \n",
    "#     plot_confusion_matrix(rf, x_test, y_test)\n",
    "    param_grid = {\n",
    "     'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [100, 250, 300, 350, 450],\n",
    "    'min_samples_split': [5, 8,10, 15],\n",
    "    'min_samples_leaf': [3, 5, 10, 15],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "    standard = StandardScaler()\n",
    "    x_train[['amount_tsh', 'gps_height', 'population', 'time_passed', 'longitude', 'latitude']] = standard.fit_transform(\n",
    "                                 x_train[['amount_tsh', 'gps_height', 'population', 'time_passed', 'longitude', 'latitude']]\n",
    "    )\n",
    "    x_test[['amount_tsh', 'gps_height', 'population', 'time_passed', 'longitude', 'latitude']] = standard.fit_transform(\n",
    "        x_test[['amount_tsh', 'gps_height', 'population', 'time_passed', 'longitude', 'latitude']]\n",
    "    )\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 7, n_repeats = 5)\n",
    "    gs = RandomizedSearchCV(estimator = rf, param_distributions = param_grid, cv = cv, n_jobs = 13, verbose = 2, \n",
    "                            n_iter = 75)\n",
    "\n",
    "    gs.fit(x_train, y_train)\n",
    "    pickle.dump(gs, open(f'../../models/Basins/{i}_GridSearch.p', 'wb'))\n",
    "    basin_dict = dict(model = gs, x_train = x_train, y_train = y_train, x_test = x_test, y_test = y_test) \n",
    "    basin_model_dict[i] = basin_dict\n",
    "    \n",
    "\n",
    "pickle.dump(basin_model_dict, open(f'../../models/Basins/TunedModels.p', 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, len(basin_model_dict.keys()))\n",
    "for idx, i in enumerate(basin_model_dict.keys()): \n",
    "    print(i)\n",
    "    basin_dict = basin_model_dict[i]\n",
    "    model = basin_dict['model']\n",
    "    print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dict = {'Lake Nyasa' : 'nya', 'Lake Victoria' : 'vic', 'Pangani' : 'pang', 'Ruvuma / Southern Coast' : 'ruv', \\\n",
    "                 'Internal' : 'int', 'Lake Tanganyika' : 'tang', 'Wami / Ruvu' : 'wami', 'Rufiji' : 'ruf',\n",
    "             'Lake Rukwa' : 'rukwa'}\n",
    "\n",
    "\n",
    "new_dict = {y:i for i,y in orig_dict.items()}\n",
    "# new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize = (12,7))\n",
    "cm_dict = {}\n",
    "for idx, i in enumerate(basin_model_dict.keys()): \n",
    "    basin_dict = basin_model_dict[i]\n",
    "    model =basin_dict['model'].best_estimator_\n",
    "    x_test = basin_dict['x_test']\n",
    "    y_test = basin_dict['y_test']\n",
    "    plot_confusion_matrix(model, x_test, y_test, \n",
    "                          display_labels = ['F', 'R'], ax = ax[idx//3, idx%3], normalize = 'true')\n",
    "    ax[idx//3, idx%3].set_title(f'{new_dict[i]}')\n",
    "    cm_dict[i] = confusion_matrix(y_test, model.predict(x_test))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(f'figures/BASINS_confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cm_dict, open(f'../../models/Basins/BasinCMDict.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_model_dict = pickle.load(open(f'../../models/Basins/TunedModels.p', 'rb'))\n",
    "pbar = tqdm(basin_model_dict.keys())\n",
    "final_results = {} \n",
    "for bas in pbar: \n",
    "    pbar.set_description(f'KFold: {bas}')\n",
    "    model = basin_model_dict[bas]['model'].best_estimator_\n",
    "    x_train = basin_model_dict[bas]['x_train']\n",
    "    x_test = basin_model_dict[bas]['x_test']\n",
    "    X = x_train.append(x_test, ignore_index = True)\n",
    "    \n",
    "    y_train = pd.DataFrame(basin_model_dict[bas]['y_train'], columns = ['target'])\n",
    "    y_test = pd.DataFrame(basin_model_dict[bas]['y_test'], columns = ['target'])\n",
    "    y = y_train.append(y_test, ignore_index = True)\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 10)\n",
    "    scores = cross_val_score(model, X, y.target.values, scoring = 'accuracy', cv = cv, n_jobs = 12, \n",
    "                             error_score = 'raise')\n",
    "    final_results[bas]=  scores\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "names = [new_dict[i] for i in final_results.keys()]\n",
    "results = [i[1] for i in final_results.items()]\n",
    "plt.boxplot(results, labels = names)\n",
    "plt.title('Accuracy By Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/ByRegionKFold.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "\n",
    "scores = []\n",
    "basins = []\n",
    "basin_model_dict= {} \n",
    "pbar = os.listdir('../../data/processed/pickles/basins/')\n",
    "for i in os.listdir('../../data/processed/pickles/basins/'):\n",
    "    if i == '.DS_Store': \n",
    "        continue \n",
    "    basins.append(i)\n",
    "    #pbar.set_description(f'Testing Classifier for: {i.upper()}')\n",
    "    x_train = pickle.load(open(f'../../data/processed/pickles/basins/{i}/x_train.p', 'rb'))\n",
    "    x_test = pickle.load(open(f'../../data/processed/pickles/basins/{i}/x_test.p', 'rb'))\n",
    "    y_train = pickle.load(open(f'../../data/processed/pickles/basins/{i}/y_train.p', 'rb'))\n",
    "    y_test = pickle.load(open(f'../../data/processed/pickles/basins/{i}/y_test.p', 'rb'))\n",
    "    \n",
    "    x_train.drop('basin', axis =1, inplace = True)\n",
    "    x_test.drop('basin', axis =1, inplace = True)\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()   \n",
    "    \n",
    "   \n",
    "    standard = StandardScaler()\n",
    "    x_train[['amount_tsh', 'gps_height', 'population', 'time_passed', 'longitude', 'latitude']] = standard.fit_transform(\n",
    "                                 x_train[['amount_tsh', 'gps_height', 'population', 'time_passed', 'longitude', 'latitude']]\n",
    "    )\n",
    "    x_test[['amount_tsh', 'gps_height', 'population', 'time_passed', 'longitude', 'latitude']] = standard.fit_transform(\n",
    "        x_test[['amount_tsh', 'gps_height', 'population', 'time_passed', 'longitude', 'latitude']]\n",
    "    )\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 3)\n",
    "    classifiers = [DecisionTreeClassifier(), RandomForestClassifier()]\n",
    "    sclf = StackingCVClassifier(classifiers = classifiers, meta_classifier = LogisticRegression(), random_state = 10)\n",
    "\n",
    "    params = {\n",
    "    'decisiontreeclassifier__criterion': ['gini', 'entropy'],\n",
    "    'decisiontreeclassifier__splitter': ['best', 'random'],\n",
    "    'decisiontreeclassifier__max_depth': [None, 125, 500, 1000],\n",
    "    'decisiontreeclassifier__min_samples_split': [8, 10, 15],\n",
    "    'decisiontreeclassifier__min_samples_leaf': [3, 5, 10], \n",
    "    'decisiontreeclassifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'decisiontreeclassifier__max_leaf_nodes': [None, 25,  50],\n",
    "    \n",
    "    'randomforestclassifier__criterion': ['gini', 'entropy'],\n",
    "    'randomforestclassifier__max_depth': [None, 50, 100, 150, 200],\n",
    "    'randomforestclassifier__min_samples_split': [8,10, 15],\n",
    "    'randomforestclassifier__min_samples_leaf': [3, 5, 10],\n",
    "    'randomforestclassifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'randomforestclassifier__max_leaf_nodes': [None, 25, 50], \n",
    "    'randomforestclassifier__bootstrap': [False, True],\n",
    "      \n",
    "    'meta_classifier__C': [.1, .5, 1, 1.25, 1.5, 2], \n",
    "    'meta_classifier__max_iter': [100, 1000,2000],\n",
    "    'meta_classifier__penalty': ['l1', 'l2'],\n",
    "    'meta_classifier__solver': ['sag', 'saga', 'liblinear', 'lbfgs', 'newton-cg'],\n",
    "    'meta_classifier__multi_class': ['ovr', 'multinomial']    \n",
    "}\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 3)\n",
    "    gs = RandomizedSearchCV(estimator = sclf, param_distributions = params, cv = cv, n_jobs = 13, verbose = 1, n_iter = 13)\n",
    "    gs.fit(x_train,y_train)\n",
    "    pickle.dump(gs, open(f'../../models/Basins/{i}_GridSearch.p', 'wb'))\n",
    "    basin_dict = dict(model = gs, x_train = x_train, y_train = y_train, x_test = x_test, y_test = y_test) \n",
    "    basin_model_dict[i] = basin_dict\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
