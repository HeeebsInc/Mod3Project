{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 35 \n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X: (57247, 55)\tOriginal y: (57247, 1)\n",
      "Train X: (42935, 54)\tTrain y: (42935, 1)\n",
      "Test X: (14312, 54)\tTest y: (14312, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_pickles(): \n",
    "    x_train = pickle.load(open(f'../../data/processed/pickles/cluster_x_train.p', 'rb'))\n",
    "    x_test = pickle.load(open(f'../../data/processed/pickles/cluster_x_test.p', 'rb'))\n",
    "    y_train = pickle.load(open(f'../../data/processed/pickles/cluster_y_train.p', 'rb'))\n",
    "    y_test = pickle.load(open(f'../../data/processed/pickles/cluster_y_test.p', 'rb'))\n",
    "    X = pickle.load(open('../../data/processed/pickles/cluster_X.p', 'rb'))\n",
    "    y = pickle.load(open('../../data/processed/pickles/cluster_y.p', 'rb'))\n",
    "\n",
    "    return (x_train, x_test, y_train, y_test), (X,y)\n",
    "\n",
    "(x_train, x_test, y_train, y_test), (X,y) = get_pickles()\n",
    "\n",
    "print(f'Original X: {X.shape}\\tOriginal y: {y.shape}')\n",
    "print(f'Train X: {x_train.shape}\\tTrain y: {y_train.shape}')\n",
    "print(f'Test X: {x_test.shape}\\tTest y: {y_test.shape}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "standard = StandardScaler() \n",
    "x_train[['amount_tsh', 'gps_height', \n",
    "         'population', 'time_passed']] = standard.fit_transform(x_train[['amount_tsh', \n",
    "                                                                         'gps_height', 'population', 'time_passed']])\n",
    "unique_clusters = x_train.cluster.unique() \n",
    "complete_x = x_train.append(x_test, ignore_index = False)\n",
    "complete_y = y_train.append(y_test, ignore_index = False)\n",
    "complete_df = complete_x\n",
    "complete_df['target'] = complete_y.target.values\n",
    "\n",
    "y_train = y_train.target.values.ravel()\n",
    "y_test = y_test.target.values.ravel()\n",
    "y = y.target.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'log': LogisticRegression(max_iter = 2000),\n",
    "           'knn': KNeighborsClassifier(),\n",
    "          'dt': DecisionTreeClassifier(), 'Gaussian': GaussianNB(), 'LDA': LinearDiscriminantAnalysis(),\n",
    "          'rf': RandomForestClassifier(),\n",
    "        }\n",
    "#create stacked model\n",
    "stack_m = [] \n",
    "for model, m in models.items(): \n",
    "    stack_m.append((model, m))\n",
    "stack_model = StackingClassifier(estimators = stack_m, final_estimator = LogisticRegression(), cv = 5)\n",
    "models['stacked'] = stack_model\n",
    "\n",
    "\n",
    "stack_model = models['stacked']\n",
    "\n",
    "def get_stacked(train, test): \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing 8 Features || Best AUC: 0 || Best n: 0:   0%|                                                                                                              | 0/45 [00:49<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The classifier does not expose \"coef_\" or \"feature_importances_\" attributes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-04ba466705ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mrfe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\heeeb\\anaconda3\\envs\\codeacademy\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \"\"\"\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\heeeb\\anaconda3\\envs\\codeacademy\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mcoefs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'feature_importances_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcoefs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m                 raise RuntimeError('The classifier does not expose '\n\u001b[0m\u001b[0;32m    199\u001b[0m                                    \u001b[1;34m'\"coef_\" or \"feature_importances_\" '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m                                    'attributes')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The classifier does not expose \"coef_\" or \"feature_importances_\" attributes"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "best_score = 0 \n",
    "best_i = 0\n",
    "r_back = [i for i in range(8,53)]\n",
    "pbar = tqdm(r_back)\n",
    "for i in pbar: \n",
    "    pbar.set_description(f'Testing {i} Features || Best AUC: {best_score} || Best n: {best_i}')\n",
    "    rfe = RFE(stack_model, n_features_to_select = i, step = 2)\n",
    "\n",
    "    rfe.fit(x_train,y_train)\n",
    "    pred = rfe.predict(x_test)\n",
    "    roc_auc = roc_auc_score(y_test, pred)\n",
    "    if roc_auc > best_score: \n",
    "        best_score = roc_auc \n",
    "        best_i = i\n",
    "    #masks for columns that are important\n",
    "        column_masks = rfe.support_\n",
    "\n",
    "        orig_columns = x_train.columns\n",
    "        new_columns = [x for x,y in zip(orig_columns, column_masks) if y == True]\n",
    "        pickle.dump(new_columns, open('../../models/Stacked_Columns.p', 'wb'))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
