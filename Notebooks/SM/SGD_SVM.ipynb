{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_selection import RFE \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X: (57247, 53)\tOriginal y: (57247, 1)\n",
      "Train X: (48659, 53)\tTrain y: (48659, 1)\n",
      "Test X: (8588, 53)\tTest y: (8588, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_pickles(): \n",
    "    x_train = pickle.load(open(f'../../data/processed/pickles/x_train.p', 'rb'))\n",
    "    x_test = pickle.load(open(f'../../data/processed/pickles/x_test.p', 'rb'))\n",
    "    y_train = pickle.load(open(f'../../data/processed/pickles/y_train.p', 'rb'))\n",
    "    y_test = pickle.load(open(f'../../data/processed/pickles/y_test.p', 'rb'))\n",
    "    X = pickle.load(open('../../data/processed/pickles/X.p', 'rb'))\n",
    "    y = pickle.load(open('../../data/processed/pickles/y.p', 'rb'))\n",
    "\n",
    "    return (x_train, x_test, y_train, y_test), (X,y)\n",
    "\n",
    "(x_train, x_test, y_train, y_test), (X,y) = get_pickles()\n",
    "\n",
    "\n",
    "print(f'Original X: {X.shape}\\tOriginal y: {y.shape}')\n",
    "print(f'Train X: {x_train.shape}\\tTrain y: {y_train.shape}')\n",
    "print(f'Test X: {x_test.shape}\\tTest y: {y_test.shape}')\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "\n",
    "standard = StandardScaler() \n",
    "\n",
    "x_train[['amount_tsh', 'gps_height', \n",
    "         'population', 'time_passed']] = standard.fit_transform(x_train[['amount_tsh', \n",
    "                                                                         'gps_height', 'population', 'time_passed']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                            early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                            fit_intercept=True, l1_ratio=0.15,\n",
       "                            learning_rate='optimal', loss='hinge',\n",
       "                            max_iter=1000, n_iter_no_change=5, n_jobs=8,\n",
       "                            penalty='l2', power_t=0.5, random_state=None,\n",
       "                            shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                            verbose=0, warm_start=False),\n",
       "    n_features_to_select=5, step=1, verbose=2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SGDClassifier(n_jobs = 8)\n",
    "rfe = RFE(svm, n_features_to_select = 5, verbose = 2)\n",
    "rfe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 0.7078481602235678\n",
      "[False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False  True False False  True False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False]\n",
      "['basin_Lake Rukwa', 'extract_climax', 'waterpoint_communal standpipe multiple', 'waterpoint_other', 'quantity_dry']\n"
     ]
    }
   ],
   "source": [
    "print('Score', rfe.score(x_test,y_test))\n",
    "#masks for columns that are important\n",
    "column_masks = rfe.support_\n",
    "print(column_masks)\n",
    "\n",
    "orig_columns = x_train.columns\n",
    "new_columns = [x for x,y in zip(orig_columns, column_masks) if y == True]\n",
    "print(new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3840 candidates, totalling 19200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1953 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2624 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done 5540 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done 7242 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 9104 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 11130 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 13316 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 15666 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 17648 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 18985 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 19200 out of 19200 | elapsed:  8.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                     class_weight=None, early_stopping=False,\n",
       "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                                     l1_ratio=0.15, learning_rate='optimal',\n",
       "                                     loss='hinge', max_iter=1000,\n",
       "                                     n_iter_no_change=5, n_jobs=None,\n",
       "                                     penalty='l2', power_t=0.5,\n",
       "                                     random_state=None, shuffle=True, tol=0.001,\n",
       "                                     validation_fraction=0...\n",
       "             param_grid={'alpha': [0.001, 0.0001, 0.1, 0.01],\n",
       "                         'early_stopping': [True, False],\n",
       "                         'epsilon': [0.1, 0.01],\n",
       "                         'l1_ratio': [0.15, 0.45, 0.01, 0.015],\n",
       "                         'loss': ['hinge', 'log', 'perceptron',\n",
       "                                  'modified_huber', 'squared_hinge'],\n",
       "                         'max_iter': [1000, 3000], 'penalty': ['l2', 'l1'],\n",
       "                         'tol': [0.001, 0.01, 0.1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new = x_train[new_columns]\n",
    "x_test_new= x_test[new_columns]\n",
    "param_grid = {\n",
    "    'loss': ['hinge', 'log', 'perceptron', 'modified_huber', 'squared_hinge'],\n",
    "    'penalty': ['l2', 'l1'],\n",
    "    'alpha': [.001, .0001, .1, .01],\n",
    "    'l1_ratio': [.15, .45, .01, .015],\n",
    "    'max_iter': [1000, 3000],\n",
    "    'tol': [.001, .01, .1],\n",
    "    'epsilon': [.1, .01],\n",
    "    'early_stopping': [True, False]\n",
    "}\n",
    "svm = SGDClassifier()\n",
    "gs = GridSearchCV(svm, param_grid = param_grid, verbose = 2, n_jobs = -1)\n",
    "gs.fit(x_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gs, open('../../models/SGD_SVM_GridSearch.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "              early_stopping=True, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.45, learning_rate='optimal', loss='modified_huber',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.6934094084769445\n"
     ]
    }
   ],
   "source": [
    "x_test_new= x_test[new_columns]\n",
    "\n",
    "svm_tuned = SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
    "              early_stopping=True, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "              l1_ratio=0.15, learning_rate='optimal', loss='squared_hinge',\n",
    "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
    "              power_t=0.5, random_state=None, shuffle=True, tol=0.1,\n",
    "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "\n",
    "svm_tuned.fit(x_train_new,y_train)\n",
    "\n",
    "print(f'Test Score: {svm_tuned.score(x_test_new,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
