{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, GridSearchCV\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_selection import RFE, SelectFromModel\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X: (57247, 55)\tOriginal y: (57247, 1)\n",
      "Train X: (42935, 54)\tTrain y: (42935, 1)\n",
      "Test X: (14312, 54)\tTest y: (14312, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_pickles(): \n",
    "    x_train = pickle.load(open(f'../../../data/processed/pickles/cluster_x_train.p', 'rb'))\n",
    "    x_test = pickle.load(open(f'../../../data/processed/pickles/cluster_x_test.p', 'rb'))\n",
    "    y_train = pickle.load(open(f'../../../data/processed/pickles/cluster_y_train.p', 'rb'))\n",
    "    y_test = pickle.load(open(f'../../../data/processed/pickles/cluster_y_test.p', 'rb'))\n",
    "    X = pickle.load(open('../../../data/processed/pickles/cluster_X.p', 'rb'))\n",
    "    y = pickle.load(open('../../../data/processed/pickles/cluster_y.p', 'rb'))\n",
    "\n",
    "    return (x_train, x_test, y_train, y_test), (X,y)\n",
    "\n",
    "(x_train, x_test, y_train, y_test), (X,y) = get_pickles()\n",
    "\n",
    "\n",
    "print(f'Original X: {X.shape}\\tOriginal y: {y.shape}')\n",
    "print(f'Train X: {x_train.shape}\\tTrain y: {y_train.shape}')\n",
    "print(f'Test X: {x_test.shape}\\tTest y: {y_test.shape}')\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla ROC Score: 0.713695346683728\n"
     ]
    }
   ],
   "source": [
    "#Vanilla \n",
    "lg = LogisticRegression(max_iter = 3000) \n",
    "lg.fit(x_train,y_train)\n",
    "test_pred = lg.predict(x_test)\n",
    "print(f'Vanilla ROC Score: {roc_auc_score(y_test, test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing 54 PCA Features || Best AUC: 0.7145282072313638 || Best n: 41: 100%|██████████████████████████████████████████████████████████████████████████████| 54/54 [02:26<00:00,  2.72s/it]\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression(max_iter = 3000)\n",
    "best_score = 0 \n",
    "best_i = 0\n",
    "r_back = [i for i in range(1,len(x_train.columns)+1)]\n",
    "pbar = tqdm(r_back)\n",
    "for i in pbar: \n",
    "    pbar.set_description(f'Testing {i} PCA Features || Best AUC: {best_score} || Best n: {best_i}')\n",
    "    pca = PCA(n_components = i)\n",
    "    pca.fit(x_train)\n",
    "    x_train_new = pca.transform(x_train)\n",
    "    x_test_new = pca.transform(x_test)\n",
    "    lg.fit(x_train_new,y_train)\n",
    "    pred = lg.predict(x_test_new)\n",
    "    roc_auc = roc_auc_score(y_test, pred)\n",
    "    if roc_auc > best_score: \n",
    "        best_score = roc_auc \n",
    "        best_i = i\n",
    "    #masks for columns that are important\n",
    "        pickle.dump(best_i, open('../../../models/Logistic_PCA.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing 52 Features || Best AUC: 0.7120531464795856 || Best n: 51: 100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [05:44<00:00,  7.65s/it]\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression(max_iter = 3000)\n",
    "best_score = 0 \n",
    "best_i = 0\n",
    "r_back = [i for i in range(8,53)]\n",
    "pbar = tqdm(r_back)\n",
    "for i in pbar: \n",
    "    pbar.set_description(f'Testing {i} Features || Best AUC: {best_score} || Best n: {best_i}')\n",
    "    rfe = RFE(lg, n_features_to_select = i, step = 3)\n",
    "\n",
    "    rfe.fit(x_train,y_train)\n",
    "    pred = rfe.predict(x_test)\n",
    "    roc_auc = roc_auc_score(y_test, pred)\n",
    "    if roc_auc > best_score: \n",
    "        best_score = roc_auc \n",
    "        best_i = i\n",
    "    #masks for columns that are important\n",
    "        column_masks = rfe.support_\n",
    "\n",
    "        orig_columns = x_train.columns\n",
    "        new_columns = [x for x,y in zip(orig_columns, column_masks) if y == True]\n",
    "        pickle.dump(new_columns, open('../../../models/LGColumns.p', 'wb'))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gps_height', 'permit', 'time_passed', 'basin_Lake Nyasa', 'basin_Lake Victoria', 'basin_Pangani', 'basin_Ruvuma / Southern Coast', 'basin_Internal', 'basin_Lake Tanganyika', 'basin_Wami / Ruvu', 'basin_Rufiji', 'basin_Lake Rukwa', 'extract_gravity', 'extract_submersible', 'extract_swn 80', 'extract_nira/tanira', 'extract_india mark ii', 'extract_extract_other', 'extract_ksb', 'extract_windmill', 'extract_afridev', 'extract_mono', 'extract_india mark iii', 'extract_cemo', 'extract_climax', 'extract_walimi', 'waterpoint_communal standpipe', 'waterpoint_communal standpipe multiple', 'waterpoint_hand pump', 'waterpoint_other', 'waterpoint_improved spring', 'waterpoint_cattle trough', 'waterpoint_dam', 'source_spring', 'source_rainwater harvesting', 'source_dam', 'source_machine dbh', 'source_other', 'source_shallow well', 'source_river', 'source_hand dtw', 'source_lake', 'quality_soft', 'quality_salty', 'quality_milky', 'quality_fluoride', 'quality_coloured', 'quantity_enough', 'quantity_insufficient', 'quantity_dry', 'quantity_seasonal', 'cluster']\n"
     ]
    }
   ],
   "source": [
    "columns = pickle.load(open('../../../models/LGColumns.p', 'rb'))\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=11)]: Done  19 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=11)]: Done 100 out of 100 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=11,\n",
       "             param_grid={'max_iter': [100, 1000], 'multi_class': ['ovr'],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['sag', 'saga', 'liblinear', 'lbfgs',\n",
       "                                    'newton-cg']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'max_iter': [100, 1000,],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['sag', 'saga', 'liblinear', 'lbfgs', 'newton-cg'],\n",
    "    'multi_class': ['ovr']  \n",
    "}\n",
    "x_train_new = x_train[columns]\n",
    "x_test_new= x_test[columns]\n",
    "log = LogisticRegression()\n",
    "gs = GridSearchCV(log, param_grid = param_grid, verbose = 2, n_jobs = 11)\n",
    "gs.fit(x_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.dump(gs, open('../../../models/Logistic_GridSearch.p', 'wb'))\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned ROC Score: 0.7120797456081445\n",
      "Tuned ACC Score: 0.7276411403018446\n"
     ]
    }
   ],
   "source": [
    "log_tuned = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "\n",
    "log_tuned.fit(x_train_new, y_train)\n",
    "\n",
    "test_pred = log_tuned.predict(x_test_new)\n",
    "\n",
    "\n",
    "print(f'Tuned ROC Score: {roc_auc_score(y_test, test_pred)}')\n",
    "print(f'Tuned ACC Score: {log_tuned.score(x_test_new, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
